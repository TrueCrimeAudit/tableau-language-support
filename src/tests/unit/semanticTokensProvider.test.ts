// src/tests/unit/semanticTokensProvider.test.ts\n\nimport { TextDocument } from 'vscode-languageserver-textdocument';\nimport { provideSemanticTokens } from '../../semanticTokensProvider';\nimport { parsedDocumentCache } from '../../common';\nimport { IncrementalParser } from '../../incrementalParser';\n\ndescribe('Semantic Tokens Provider', () => {\n    beforeEach(() => {\n        // Clear cache\n        parsedDocumentCache.clear();\n    });\n    \n    describe('Basic Token Classification', () => {\n        it('should classify function names as functions', () => {\n            const document = createTestDocument('SUM([Sales])');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify field references as variables', () => {\n            const document = createTestDocument('[Sales]');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify keywords correctly', () => {\n            const document = createTestDocument('IF [Sales] > 100 THEN \"High\" ELSE \"Low\" END');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify string literals as strings', () => {\n            const document = createTestDocument('\"Hello World\"');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify numeric literals as constants', () => {\n            const document = createTestDocument('123.45');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify operators correctly', () => {\n            const document = createTestDocument('[Sales] + [Profit] * 2');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify comments correctly', () => {\n            const document = createTestDocument('SUM([Sales]) // This is a comment');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n    });\n    \n    describe('Complex Expression Classification', () => {\n        it('should classify IF expressions correctly', () => {\n            const document = createTestDocument(`\n                IF [Sales] > 1000 THEN\n                    \"High Sales\"\n                ELSEIF [Sales] > 500 THEN\n                    \"Medium Sales\"\n                ELSE\n                    \"Low Sales\"\n                END\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify CASE expressions correctly', () => {\n            const document = createTestDocument(`\n                CASE [Category]\n                    WHEN \"Furniture\" THEN [Sales] * 0.1\n                    WHEN \"Technology\" THEN [Sales] * 0.15\n                    ELSE [Sales] * 0.05\n                END\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify LOD expressions correctly', () => {\n            const document = createTestDocument('{ FIXED [Region] : SUM([Sales]) }');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should classify nested function calls correctly', () => {\n            const document = createTestDocument('ROUND(SUM(AVG([Sales])), 2)');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n    });\n    \n    describe('Token Data Format', () => {\n        it('should return tokens in correct LSP format', () => {\n            const document = createTestDocument('SUM([Sales])');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens).toHaveProperty('data');\n            expect(Array.isArray(tokens.data)).toBe(true);\n            \n            // LSP semantic tokens are encoded as arrays of integers\n            tokens.data.forEach(value => {\n                expect(typeof value).toBe('number');\n                expect(Number.isInteger(value)).toBe(true);\n            });\n        });\n        \n        it('should encode token positions correctly', () => {\n            const document = createTestDocument('SUM([Sales])');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens.data.length).toBeGreaterThan(0);\n            \n            // Tokens should be encoded in groups of 5 integers\n            // [deltaLine, deltaStart, length, tokenType, tokenModifiers]\n            expect(tokens.data.length % 5).toBe(0);\n        });\n        \n        it('should handle multi-line documents correctly', () => {\n            const document = createTestDocument(`\n                SUM([Sales])\n                AVG([Profit])\n                COUNT([Orders])\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n    });\n    \n    describe('Token Type Consistency', () => {\n        it('should consistently classify the same function names', () => {\n            const document = createTestDocument('SUM([Sales]) + SUM([Profit])');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n            \n            // Both SUM occurrences should have the same token type\n            // This would require parsing the token data to verify\n        });\n        \n        it('should consistently classify the same field references', () => {\n            const document = createTestDocument('[Sales] + [Sales] * 2');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should consistently classify the same keywords', () => {\n            const document = createTestDocument(`\n                IF [Sales] > 100 THEN \"High\" END +\n                IF [Profit] > 50 THEN \"Good\" END\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n    });\n    \n    describe('Edge Cases', () => {\n        it('should handle empty documents', () => {\n            const document = createTestDocument('');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n            expect(tokens.data.length).toBe(0);\n        });\n        \n        it('should handle whitespace-only documents', () => {\n            const document = createTestDocument('   \\n  \\t  \\n   ');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n        });\n        \n        it('should handle malformed expressions gracefully', () => {\n            const document = createTestDocument('SUM([Sales] +');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n        });\n        \n        it('should handle documents with only comments', () => {\n            const document = createTestDocument('// This is just a comment\\n// Another comment');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n        });\n        \n        it('should handle very long lines', () => {\n            const longExpression = Array.from({ length: 100 }, (_, i) => `[Field${i}]`).join(' + ');\n            const document = createTestDocument(longExpression);\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n    });\n    \n    describe('Performance', () => {\n        it('should provide semantic tokens quickly for normal documents', () => {\n            const document = createTestDocument(`\n                IF [Sales] > 1000 THEN\n                    CASE [Category]\n                        WHEN \"Furniture\" THEN SUM([Profit])\n                        ELSE AVG([Discount])\n                    END\n                ELSE\n                    COUNT([Orders])\n                END\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const startTime = Date.now();\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            const duration = Date.now() - startTime;\n            \n            expect(tokens).toBeDefined();\n            expect(duration).toBeLessThan(100); // Should be fast\n        });\n        \n        it('should handle large documents efficiently', () => {\n            const largeContent = Array.from({ length: 200 }, (_, i) => \n                `IF [Field${i}] > ${i} THEN SUM([Value${i}]) ELSE AVG([Other${i}]) END`\n            ).join('\\n');\n            \n            const document = createTestDocument(largeContent);\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const startTime = Date.now();\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            const duration = Date.now() - startTime;\n            \n            expect(tokens).toBeDefined();\n            expect(duration).toBeLessThan(500); // Should handle large documents\n        });\n        \n        it('should handle repeated calls efficiently', () => {\n            const document = createTestDocument('SUM([Sales]) + AVG([Profit])');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const startTime = Date.now();\n            \n            for (let i = 0; i < 100; i++) {\n                provideSemanticTokens(document, parsedDoc);\n            }\n            \n            const duration = Date.now() - startTime;\n            expect(duration).toBeLessThan(200); // Should cache or be very efficient\n        });\n    });\n    \n    describe('Token Coverage', () => {\n        it('should provide tokens for all significant elements', () => {\n            const document = createTestDocument(`\n                // Comment\n                IF [Sales] > 100 THEN\n                    SUM([Profit]) * 1.1\n                ELSE\n                    \"Low\"\n                END\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n            \n            // Should have tokens for:\n            // - Comment\n            // - Keywords (IF, THEN, ELSE, END)\n            // - Function (SUM)\n            // - Field reference ([Sales], [Profit])\n            // - Numbers (100, 1.1)\n            // - String (\"Low\")\n            // - Operators (>, *)\n        });\n        \n        it('should not miss tokens in complex nested expressions', () => {\n            const document = createTestDocument(`\n                ROUND(\n                    SUM(\n                        IF [Category] = \"Furniture\" THEN\n                            [Sales] * 1.1\n                        ELSE\n                            [Sales]\n                        END\n                    ),\n                    2\n                )\n            `);\n            \n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n    });\n    \n    describe('Error Recovery', () => {\n        it('should provide partial tokens for partially valid expressions', () => {\n            const document = createTestDocument('SUM([Sales]) + INVALID_FUNCTION(');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n            \n            // Should still provide tokens for the valid parts\n            expect(tokens.data.length).toBeGreaterThan(0);\n        });\n        \n        it('should handle syntax errors gracefully', () => {\n            const document = createTestDocument('IF [Sales] > 100 THEN THEN ELSE');\n            const parsedDoc = IncrementalParser.parseDocumentIncremental(document);\n            \n            const tokens = provideSemanticTokens(document, parsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n        });\n        \n        it('should handle missing parsed document gracefully', () => {\n            const document = createTestDocument('SUM([Sales])');\n            \n            // Create minimal parsed document\n            const emptyParsedDoc = {\n                document,\n                symbols: [],\n                diagnostics: [],\n                lineSymbols: new Map(),\n                lastChangeVersion: 1,\n                changedLines: new Set()\n            };\n            \n            const tokens = provideSemanticTokens(document, emptyParsedDoc);\n            \n            expect(tokens).toBeDefined();\n            expect(tokens.data).toBeDefined();\n            expect(Array.isArray(tokens.data)).toBe(true);\n        });\n    });\n});\n\n/**\n * Helper function to create test documents\n */\nfunction createTestDocument(\n    content: string, \n    version: number = 1, \n    uri: string = 'test://test.twbl'\n): TextDocument {\n    return TextDocument.create(uri, 'tableau', version, content);\n}\n"